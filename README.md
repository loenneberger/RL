# ğŸš• Reinforcement Learning mit Q-Learning und SARSA auf Taxi-v3

Dieses Projekt implementiert und vergleicht zwei klassische tabellarische RL-Algorithmen â€“ **Q-Learning** und **SARSA** â€“ in der bekannten Umgebung `Taxi-v3` aus dem Gymnasium-Toolkit.

Ziel ist es, einem Agenten beizubringen, in einer kleinen Stadt effizient Passagiere abzuholen und korrekt abzusetzen.

## ğŸ“„ Inhalt

- `RL_taxi.ipynb` â€“ Hauptnotebook mit vollstÃ¤ndiger Implementierung, Training, Visualisierung und Auswertung
- `requirements.txt` â€“ Python-AbhÃ¤ngigkeiten fÃ¼r lokale AusfÃ¼hrung
- `README.md` â€“ Dieses Dokument

## ğŸš€ Schnellstart (empfohlen)

Die einfachste MÃ¶glichkeit ist die AusfÃ¼hrung in **Google Colab**:

[ğŸ“‚ Notebook jetzt in Colab Ã¶ffnen](https://colab.research.google.com/github/loenneberger/RL/blob/main/RL_taxi.ipynb)


## Alternativ: Lokal ausfÃ¼hren

### 1. Repository klonen
  git clone https://github.com/loenneberger/RL.git
  
  cd RL

### 2. (Optional) Virtuelle Umgebung erstellen
  python -m venv venv
  
  source venv/bin/activate  # Windows: venv\Scripts\activate

### 3. AbhÃ¤ngigkeiten installieren
  pip install -r requirements.txt

### 4. Notebook starten
  jupyter notebook RL_taxi.ipynb

## ğŸ“Š Features
Tabellarisches Q-Learning (Off-Policy)

Tabellarisches SARSA (On-Policy)

Epsilon-Greedy Exploration mit Decay

Lernkurven mit Moving Average

Visuelle Beispiel-Episoden (GIF-Animationen)

Vergleich der Agentenleistung


## ğŸ” Hinweis
Das Projekt wurde im Rahmen einer Reinforcement-Learning-Lehrveranstaltung umgesetzt und ist besonders auf einfache Reproduzierbarkeit in Colab ausgelegt.

Teile dieses Codes wurden mit UnterstÃ¼tzung von ChatGPT (OpenAI) generiert.
Die finalen Implementierungen wurden Ã¼berprÃ¼ft, getestet und ggf. angepasst.

